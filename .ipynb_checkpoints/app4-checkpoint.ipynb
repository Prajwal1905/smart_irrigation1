{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99ad40d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     12\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === Load CSV ===\n",
    "df = pd.read_csv(\"your_file.csv\")  # Change to your actual filename\n",
    "\n",
    "# === Rename sensor columns ===\n",
    "sensor_rename_map = {\n",
    "    'sensor_0': 'soil_moisture_1',\n",
    "    'sensor_1': 'soil_moisture_2',\n",
    "    'sensor_2': 'soil_moisture_3',\n",
    "    'sensor_3': 'air_temperature',\n",
    "    'sensor_4': 'humidity',\n",
    "    'sensor_5': 'light_intensity',\n",
    "    'sensor_6': 'soil_temperature',\n",
    "    'sensor_7': 'rain_sensor',\n",
    "    'sensor_8': 'ph_sensor',\n",
    "    'sensor_9': 'water_level',\n",
    "    'sensor_10': 'wind_speed',\n",
    "    'sensor_11': 'wind_direction',\n",
    "    'sensor_12': 'battery_voltage',\n",
    "    'sensor_13': 'solar_radiation',\n",
    "    'sensor_14': 'leaf_wetness',\n",
    "    'sensor_15': 'evapotranspiration',\n",
    "    'sensor_16': 'canopy_temperature',\n",
    "    'sensor_17': 'chlorophyll',\n",
    "    'sensor_18': 'water_salinity',\n",
    "    'sensor_19': 'nitrate_level',\n",
    "}\n",
    "df = df.rename(columns=sensor_rename_map)\n",
    "\n",
    "# === Rename parcel to zones ===\n",
    "parcel_rename_map = {\n",
    "    0: 'rice_field_zone',\n",
    "    1: 'wheat_crop_zone',\n",
    "    2: 'vegetable_plot_zone'\n",
    "}\n",
    "df['parcel'] = df['parcel'].map(parcel_rename_map)\n",
    "\n",
    "# === Feature & Label Split ===\n",
    "X = df.drop(columns=['parcel'])\n",
    "y = df['parcel']\n",
    "\n",
    "# === Encode Labels ===\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# === Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# === SMOTE Oversampling ===\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# === Random Forest ===\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "rf_preds = rf.predict(X_test)\n",
    "print(\"üå≥ Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_preds, target_names=le.classes_))\n",
    "\n",
    "# === XGBoost ===\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', scale_pos_weight=1, random_state=42)\n",
    "xgb.fit(X_train_res, y_train_res)\n",
    "xgb_preds = xgb.predict(X_test)\n",
    "print(\"‚ö° XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, xgb_preds, target_names=le.classes_))\n",
    "\n",
    "# === Confusion Matrix ===\n",
    "def plot_confusion(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(y_test, rf_preds, \"Random Forest\")\n",
    "plot_confusion(y_test, xgb_preds, \"XGBoost\")\n",
    "\n",
    "# === Feature Importance Plot ===\n",
    "def plot_feature_importance(model, feature_names, title):\n",
    "    importance = model.feature_importances_\n",
    "    indices = importance.argsort()[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.bar(range(len(importance)), importance[indices], align=\"center\", color=\"green\")\n",
    "    plt.xticks(range(len(importance)), [feature_names[i] for i in indices], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(rf, X.columns, \"üå≥ Random Forest Feature Importance\")\n",
    "plot_feature_importance(xgb, X.columns, \"‚ö° XGBoost Feature Importance\")\n",
    "\n",
    "# === Cross-Validation ===\n",
    "rf_cv_scores = cross_val_score(rf, X_train_res, y_train_res, cv=5)\n",
    "xgb_cv_scores = cross_val_score(xgb, X_train_res, y_train_res, cv=5)\n",
    "\n",
    "print(f\"üîÅ RF CV Accuracy (5-Fold): {rf_cv_scores.mean():.2f} ¬± {rf_cv_scores.std():.2f}\")\n",
    "print(f\"üîÅ XGB CV Accuracy (5-Fold): {xgb_cv_scores.mean():.2f} ¬± {xgb_cv_scores.std():.2f}\")\n",
    "\n",
    "# === Export Trained Models ===\n",
    "joblib.dump(rf, \"random_forest_model.pkl\")\n",
    "joblib.dump(xgb, \"xgboost_model.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"‚úÖ Models and Label Encoder saved for real-time usage.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
